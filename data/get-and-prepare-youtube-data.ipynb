{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c0b292",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Audio Spletting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce29474",
   "metadata": {},
   "source": [
    "This procedure performs silence-based segmentation of audio files to produce training-ready chunks. Each audio file is iteratively split at detected silences while enforcing minimum and maximum duration constraints to avoid loss or overlap. Segments are exported as individual .wav files, and their metadata (path, duration) is stored. The process runs in parallel threads for efficiency, generating a structured JSON output summarizing all segments for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import json \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent, detect_silence\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [i for i in os.listdir(\".\") if not (i.endswith(\"py\") or i.endswith(\"md\") or i.endswith(\"ipynb\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data:list[dict] = []\n",
    "\n",
    "for base_folder in folders:\n",
    "\n",
    "    audios = os.listdir(base_folder)\n",
    "    audios = [os.path.join(base_folder,audio) for audio in audios]\n",
    "\n",
    "    for audio in audios:\n",
    "        data.append({\"path\": audio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_on_silence(audio_path, min_duration=15, max_duration=40, \n",
    "                          min_silence_len=500, silence_thresh=-40):\n",
    "    \"\"\"\n",
    "    Split audio file into segments based on silence detection, ensuring no audio is lost\n",
    "    and all segments are within the specified duration limits.\n",
    "    \"\"\"\n",
    "\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    print(f\"Total audio duration: {len(audio)/1000:.2f} seconds\")\n",
    "    \n",
    "\n",
    "    min_duration_ms = min_duration * 1000\n",
    "    max_duration_ms = max_duration * 1000\n",
    "    \n",
    "    def find_split_point(audio_chunk, max_duration_ms):\n",
    "        \"\"\"Find the best point to split the audio chunk\"\"\"\n",
    "\n",
    "        silences = detect_silence(\n",
    "            audio_chunk,\n",
    "            min_silence_len=min_silence_len,\n",
    "            silence_thresh=silence_thresh\n",
    "        )\n",
    "        \n",
    "\n",
    "        for silence_start, silence_end in silences:\n",
    "            if silence_start <= max_duration_ms:\n",
    "                return silence_end\n",
    "        \n",
    "        return max_duration_ms\n",
    "\n",
    "    segments = []\n",
    "    current_position = 0\n",
    "    audio_length = len(audio)\n",
    "    \n",
    "    while current_position < audio_length:\n",
    "        print(f\"Processing position {current_position/1000:.2f}s / {audio_length/1000:.2f}s\")\n",
    "        \n",
    "\n",
    "        if (audio_length - current_position) <= max_duration_ms:\n",
    "            remaining_segment = audio[current_position:]\n",
    "            if len(remaining_segment) >= min_duration_ms:\n",
    "                segments.append(remaining_segment)\n",
    "            break\n",
    "        \n",
    "\n",
    "        end_position = min(current_position + max_duration_ms + min_silence_len, audio_length)\n",
    "        chunk = audio[current_position:end_position]\n",
    "        \n",
    "\n",
    "        split_point = find_split_point(chunk, max_duration_ms)\n",
    "        \n",
    "        segment = audio[current_position:current_position + split_point -300]\n",
    "        \n",
    "        if len(segment) >= min_duration_ms:\n",
    "            segments.append(segment)\n",
    "        \n",
    "\n",
    "        current_position += split_point\n",
    "        \n",
    "        if split_point == 0:\n",
    "            print(\"Warning: No progress made in splitting. Forcing a split.\")\n",
    "            current_position += max_duration_ms\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_segments(segments, output_prefix=\"segment\"):\n",
    "    \"\"\"\n",
    "    Export audio segments to files with duration information.\n",
    "    \"\"\"\n",
    "    output_files = []\n",
    "    total_duration = 0\n",
    "    \n",
    "    for i, segment in enumerate(segments):\n",
    "        output_path = f\"{output_prefix}_{i+1}.wav\"\n",
    "        duration_sec = len(segment) / 1000.0  \n",
    "        segment.export(output_path, format=\"wav\")\n",
    "        output_files.append({\"audio\": output_path, \"duration\" : duration_sec})\n",
    "        total_duration += duration_sec\n",
    "    return output_files, total_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cfce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = []\n",
    "segmentation_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_element(element):\n",
    "    info = {}\n",
    "    \n",
    "    try:\n",
    "        _path = element[\"path\"]\n",
    "        audio_name = _path.split(\"/\")[-1]\n",
    "        audio_path = _path\n",
    "        \n",
    "        info[\"audio\"] = _path\n",
    "        \n",
    "        segments = split_audio_on_silence(\n",
    "            audio_path,\n",
    "            min_duration=1,\n",
    "            max_duration=30,\n",
    "            min_silence_len=700,\n",
    "            silence_thresh=-30\n",
    "        )\n",
    "        \n",
    "        output_files, total_duration = export_segments(segments, f\"{audio_name[:-4]}_segment\")\n",
    "        \n",
    "        info[\"segments\"] = output_files\n",
    "        info[\"segments_duration\"] = total_duration\n",
    "        \n",
    "\n",
    "        with segmentation_lock:\n",
    "            segmentation.append(info)\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {_path}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ddb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parallel(max_workers=4):\n",
    "\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "\n",
    "        futures = [executor.submit(process_single_element, element) for element in data]\n",
    "        \n",
    "\n",
    "        for _ in tqdm(concurrent.futures.as_completed(futures), total=len(data)):\n",
    "            pass\n",
    "\n",
    "    successful = sum(1 for future in futures if future.result())\n",
    "    print(f\"Processing completed: {successful}/{len(data)} files processed successfully\")\n",
    "    \n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = generate_parallel(max_workers=32)\n",
    "with open(\"data_structured.json\", \"w\") as file_object:\n",
    "    json.dump(segmentation, file_object)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
